---
title: "Demo Portfolio for Computational Musicology 2023"
author: "John Ashley Burgoyne"
date: "Block 4"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme:
      version: 4
      bootswatch: litera
    self_contained: false
editor_options: 
  chunk_output_type: console
---

```{r, setup}
library(tidyverse)
library(plotly)
library(spotifyr)
library(compmus)
library(cowplot)
```

### Welcome to Computational Musicology 2023!

Welcome to Computational Musicology 2023!

You can access the lecture notes at the following links.

  - [Week 7 · Computational Musicology and (Audio) Visualisation](./notes/compmus2023-w07.html)
  - [Week 8 · Chromagrams](./notes/compmus2023-w08.html)

This storyboard contains further examples from each week to inspire you. You can download the raw source code of the storyboard [here](./index.Rmd).

### What makes a good corpus?

You will work a corpus of your choice throughout the course and build up an online portfolio of quantitative musical analyses. Remember that the question _Compared to what?_ hangs over all quantitative results, and so be sure to choose a corpus that allows for meaningful – but not _too_ obvious – comparisons and contrasts. Most students end up with a corpus that has 2–5 obvious groups they can compare: see a list of examples below.

The size of the corpus is not important _per se_: with computational tools, it is just as easy to work with 1000 tracks as it is to work with 10. Practically speaking, you will need at least 50–100 tracks in your corpus in order to make meaningful comparisons. At the other extreme, if your corpus gets up to 10 thousand tracks or more, computations and visualisations will probably run too slowly to be usable for an online portfolio. But anything in between can work.

You also will want a few 'highlight' tracks that you can focus on for more in-depth analysis of harmony, structure, and rhythm. These could be your favourites, a good representative of each group, or even a very oddball track that shows something interesting about how the Spotify API works!

Here is a non-exclusive list of examples, combined with questions that (by the end of the course) you could explore.

*   Geographic Region
    *   Portugal and Brazil share a common language but have distinctly different cultures. Is there a difference in style preferences for pop music between the countries? Find recent charts – or use Spotify’s regional charts – and use a corpus including both.
    *   K- and J-pop is increasingly popular outside of Asia. How much does the sound of K- and J-pop boy- or girl-bands differ from their European counterparts? Choose a selection of albums, artists, or playlists from each group based on what is popular on Spotify or external sources.
*   Label or Studio
    *   How did Motown’s competitors differ in style during its heyday? Research the most popular Motown albums, identify competitors, and make a corpus including a selection from Motown and several major competing labels.
    *   Phil Spector’s ‘Wall of Sound’ was thought to be revolutionary – but how different does it sound, really? Make a corpus balancing a number of tracks produced Phil Spector with tracks of comparable popularity from the same time period.
*   Genre
    *   Every Noise at Once compares genres with surprisingly detailed names. Choose two or more genres from Every Noise at Once and try to clarify how they differ.
    *   Fans of heavy metal are notorious for the complexity of their understanding of sub-genres. Can Spotify measure them? Find a reliable classification of heavy-metal subgenres, make a selection of tracks of two or more of these subgenres, and look for similarities and differences.
    *   How does hip-hop from the 1990s differ from hip-hop today? Find reliable playlists or make your own selection of recent and older hip-hop and look for differences within and between the time periods.
*   Composer or Artist _N.B.: Spotify’s ‘This Is:’ and ‘Composer Weekly’ series are especially helpful here._
    *   Cher has reinvented herself many times. How has her style changed over time? Look at the audio features for each major album, and see if you can cluster them into distinct style periods.
    *   How does the harpsichord music of Rameau differ from that of Couperin? Find representative albums for each composer – ideally from the same performer – and look for differences within and between the composers.
    *   Beethoven’s piano sonatas have been interpreted and re-interpreted many times since the advent of recording technology. Choose a selection of sonatas and pianists, and make a corpus including all of the relevant performances in Spotify. How well can Spotify measure the difference between pianists?
*   Playlist
    *   What does it mean to be a ‘workout’ playlist? Find several examples of workout playlists on Spotify and comparable playlists without the workout label. Is there a measurable difference between the groups?
    *   Spotify Wrapped allows you to download a list of everything you listened to last year. How does your list compare to your parents’, friends’, or partner’s? 
*   Album
    *   Which Madonna albums were the most commercially successful? Does the commercial success correspond in any way to features computable from Spotify?
    *   Is the album still a meaningful concept? For your favourite artist, check whether the songs within albums are more similar to each other than songs on different albums. Is there a measurable pattern or formula for predicting which track will be first or last?
*   Piece
    *   Jazz standards like Gershwin’s ‘Summertime’ have been covered by countless artists. Make as complete a list as possible from the Spotify catalogue. How do the covers differ from each other? Is it possible to cluster the covers into groups? How could you interpret those clusters?
    *   Mozart’s 40th Symphony is one of the best known pieces of classical music, and there are at least 40 version of it on Spotify. Are there any differences between them? Is there a measurable difference between performances on major classical labels versus performances from lesser-known artists?

***

For many reasons, you will want to make a Spotify playlist of your corpus. Playlists make statistical analysis easier and also are easy to embed to make your portfolio more interactive.

<iframe src="https://open.spotify.com/embed/playlist/4xnBi0S21rFHhhK0iGHpiS?utm_source=generator" width="100%" height="380" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture"></iframe>

### What kind of portfolio do I need to create?

Your portfolio will be a 5–10-page dashboard in the style of the R package [flexdashboard](https://rstudio.github.io/flexdashboard/articles/using.html#storyboards-1), using data from the [Spotify API](https://developer.spotify.com). Your dashboard should cover the following topics, but note that it is possible (and often desirable) for a single visualisation or tab to cover more than one topic.

  - **Background**: Which tracks did you choose? Why? What questions will the dashboard answer?
  - **Track-level features**: What insights into your corpus can be drawn from Spotify’s track-level features (valence, danceability, etc.)?
  - **Chroma features** [pitch]: What insights into your corpus can be drawn from Spotify’s chroma features?
  - **Loudness** [volume]: What insights into your corpus can be drawn from Spotify’s ‘loudness’ (power) features, either at the track level or the section level?
  - **Timbre features** [timbre]: What insights into your corpus can be drawn from Spotify’s timbre features?
  - **Temporal features** [duration]: What is notable, effective, or ineffective about structural segments, metre, rhythm, or beats in your corpus, as derived from Spotify features?
  - **Classification/regression**: Where explicit labels in your corpus exist, how strong are Spotify features for classification or regression?
  - **Clustering**: Where explicit labels in your corpus are lacking, which Spotify features generate potentially meaningful clusters?
  - **Contribution**: What have you learned from this set of analyses? Who could these conclusions benefit, and how?

Depending on your topic, you may want to start with a text-based opening like this one; alternatively, you could put your most compelling visualisation directly on the first tab and just use the commentary to introduce your corpus and research questions.

***

The grading breakdown for the portfolio is as follows. The rubric was adapted from the Association of American Colleges and Universities (AAC&U) Inquiry and Analysis and Quantitative Literacy [VALUE rubrics](https://www.aacu.org/value-rubrics).

| Component            | Points |
|----------------------|:------:|
| Corpus selection     |      6 |
| Assumptions          |      6 |
| Representation       |      6 |
| Interpretation       |      6 |
| Analysis             |      6 |
| Presentation         |      6 |
| Transfer of learning |      6 |

### Do the Dutch really listen to happier music? [track-level features]

```{r, happy}
top_50_nl <- get_playlist_audio_features("", "37i9dQZEVXbKCF6dqVpDkS")
top_50_be <- get_playlist_audio_features("", "37i9dQZEVXbJNSeeHswcKB")
top_50_world <- get_playlist_audio_features("", "37i9dQZEVXbMDoHDwVN2tF")
top_50s <-
  top_50_nl |>
  mutate(country = "The Netherlands") |>
  bind_rows(top_50_be |> mutate(country = "Belgium")) |>
  bind_rows(top_50_world |> mutate(country = "Global")) |>
  mutate(
    country = fct_relevel(country, "Global", "The Netherlands", "Belgium")
  )

february_dip <-
  top_50s |>
  ggplot(                          # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = track.popularity,
      colour = danceability,
      label = track.name           # Labels will be interactively visible.
    )
  ) +
  geom_point() +                   # Scatter plot.
  geom_rug(size = 0.1) +           # Add 'fringes' to show data distribution.
  facet_wrap(~country) +           # Separate charts per country.
  scale_x_continuous(              # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),        # Use grid-lines for quadrants only.
    minor_breaks = NULL            # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(              # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_viridis_c(          # Use the cividis palette
    option = "E",                  # Qualitative set.
    alpha = 0.8,                   # Include some transparency
    guide = "none"
  ) +
  scale_size_continuous(           # Fine-tune the sizes of each point.
    guide = "none"                 # Remove the legend for size.
  ) +
  theme_light() +                  # Use a simpler theme.
  labs(                            # Make the titles nice.
    x = "Valence",
    y = "Energy"
  )

ggplotly(february_dip)
```

***

In March 2019, [The Economist](https://www.economist.com/graphic-detail/2020/02/08/data-from-spotify-suggest-that-listeners-are-gloomiest-in-february?fsrc=scn/fb/te/bl/ed/sadsongssaysomuchdatafromspotifysuggestthatlistenersaregloomiestinfebruarygraphicdetail) published a graphic showing a worldwide dip in the emotional valence of the music to people people listen around February each year. The graphic also broke down the emotional valence for every month of the year for a selection of Spotify markets, and it revealed quite a surprise: although overall, there seemed to be two large groups, with Latin America and Spain listening to more positively valenced music than most of the rest of the world, the Netherlands stood on its own somewhere in between these two extremes. This graphic compares Spotify Top 50 in the Netherlands against Belgium, a more typical neighbouring country, as well as the worldwide average, on the standard valence--arousal model. More popular songs (worldwide) have larger dots; more danceable songs are yellow.

### The Tallis Scholars sing Josquin more slowly than La Chapelle Royale -- except for one part [chroma features].

```{r tallis}
tallis <-
  get_tidy_audio_analysis("2J3Mmybwue0jyQ0UVMYurH") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
chapelle <-
  get_tidy_audio_analysis("4ccw2IcnFt1Jv9LqQCOYDi") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)
maria_dist <-
  compmus_long_distance(
    tallis %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
    chapelle %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
    feature = pitches,
    method = "aitchison"
  )
```

```{r tallis-plot}
maria <-
  maria_dist %>%
  mutate(
    tallis = xstart + xduration / 2,
    chapelle = ystart + yduration / 2
  ) %>%
  ggplot(
    aes(
      x = tallis,
      y = chapelle,
      fill = d
    )
  ) +
  geom_tile(aes(width = xduration, height = yduration)) +
  coord_fixed() +
  scale_x_continuous(
    breaks = c(0, 60, 105, 150, 185, 220, 280, 327),
    labels =
      c(
        "Ave Maria",
        "Ave cujus conceptio",
        "Ave cujus nativitas",
        "Ave pia humilitas",
        "Ave vera virginitas",
        "Ave preclara omnibus",
        "O Mater Dei",
        ""
      ),
  ) +
  scale_y_continuous(
    breaks = c(0, 45, 80, 120, 145, 185, 240, 287),
    labels =
      c(
        "Ave Maria",
        "Ave cujus conceptio",
        "Ave cujus nativitas",
        "Ave pia humilitas",
        "Ave vera virginitas",
        "Ave preclara omnibus",
        "O Mater Dei",
        ""
      ),
  ) +
  scale_fill_viridis_c(option = "E", guide = "none") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  labs(x = "The Tallis Scholars", y = "La Chapelle Royale")
maria
```

***

This visualisation of two performances of the famous ‘Ave Maria’ setting of Josquin des Prez uses the Aitchison distance between chroma features to show how the two performances align with one another. 

For the first four stanzas, the relationship between the performances is consistent: the Tallis Scholars sing the piece somewhat more slowly than La Chapelle Royale. For the fifth stanza (*Ave vera virginitas*, starting about 3:05 into the Tallis Scholars’ performance and 2:25 into La Chapelle Royale’s), the Tallis Scholars singing faster than La Chapelle Royale, but at the beginning of the sixth stanza (*Ave preclara omnibus*, starting about 3:40 into the the Tallis Scholars’ performance and 3:05 into La Chapelle Royale’s) the Tallis Scholars return to their regular tempo relationship with La Chapelle.

Although the interactive mouse-overs from `ggplotly` are very helpful for understanding heat maps, they are very computationally intensive. Chromagrams and similarity matrices are often better as static images, like the visualisation at left.

### Vizualizing More Chroma 

```{r pop-chroma}

ewf <-
  get_tidy_audio_analysis("3cfnGXJ9bmiWvFqEO6ff8B?si=fc8b75cc5a254be0") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

loveontop <-
  get_tidy_audio_analysis("1z6WtY7X4HQJvzxC4UgkSf?si=498f16c4cea74323") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

allineed <-
  get_tidy_audio_analysis("164VgxTozx99XCinCB9ITR?si=797ce93143424c36") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)


```

```{r pop-chroma-plots}

ewf_plot <- ewf %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
    geom_vline(xintercept = 53, color = "red") +

  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "After the Love Has Gone (Earth, Wind, and Fire)") +
  theme_minimal() +
  scale_fill_viridis_c() 


loveontop_plot <- loveontop %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 184, color = "red") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Love On Top (Beyonce)") +
  theme_minimal() +
  scale_fill_viridis_c() 


allineed_plot <- allineed %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 137, color = "red") +
  geom_vline(xintercept = 186, color = "red") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "All I Need (Collier, Mahalia, Ty Dolla $ign)") +
  theme_minimal() +
  scale_fill_viridis_c() 


plot_grid(ewf_plot, loveontop_plot, allineed_plot, ncol = 1)

```

***

Chroma can be a difficult concept to grasp, especially for those without musical training. The three charts on this page visualize three pop tunes that might help make this clearer.

The first plot shows a recording of [Earth Wind and Fire's After the Love is Gone](https://open.spotify.com/track/3cfnGXJ9bmiWvFqEO6ff8B?si=55c53dd6dfc643c6), which begins in [F Major, then modulates down to E major using a chord that is a tritone away](https://www.youtube.com/watch?v=ZBpV-n10sfo) at 0:55 seconds. Note how at that moment on the spectrogram-- marked in red-- a clear concentration of energy away from F over to B!  

The second plot shows Beyonce's [Love on Top](https://open.spotify.com/track/1z6WtY7X4HQJvzxC4UgkSf?si=ad690f7ecc594205). The tune is in a singular key for the first 2/3rd's of the song, but then at around 3:04 (184 seconds) the music modulates upwards each repeat of the chorus. Note here that the the chromagram is capturing the fact that the pitch classes are going up, though her voice is also singing higher (her tessitura!). Make sure not to confuse pitch height with chroma or pitch class! 

The last plot shows the tune [All I Need](https://open.spotify.com/track/164VgxTozx99XCinCB9ITR?si=612e1f79f92b4c23), which also has a modulation, but interestingly moves from [Eb Major](https://youtube.com/watch?v=Dv9iaRJG2Yc&si=EnSIkaIECMiOmarE&t=128) to what is essentially [Bb half sharp in standard tuning (A4 = ~452.89 according to this transcription!)](https://youtube.com/watch?v=Dv9iaRJG2Yc&si=EnSIkaIECMiOmarE&t=128). This point is highlighted by the red lines on the chromagram and notice that since this "key" does not fit that well into A440, the relative magnitute of the pitches that were quite prominent (Bb + F) are not really replaced by any other pitches!

